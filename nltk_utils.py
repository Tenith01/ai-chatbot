import nltk
nltk.download('punkt')
def tokenize (sentence):
    return nltk.word_tokenize(sentence)

def Stem (word):
    pass

def bag_of_words(tokenized_sentence, all_word):
    pass